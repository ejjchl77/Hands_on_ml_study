{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 – Introduction to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공신경망(Artificial Neural Networks)은 뇌의 구조에 영감을 받아 생겨난 아이디어로 다목적(versatile), 강력(powerful), 확장성(scalable)이 뛰어나다. <br>\n",
    "수십억개의 이미지 분류, 음성인식서비스 등 크고 복잡한 기계학습에 이상적이다. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. From Biological to Artificial Neurons\n",
    "신경 생리학자 **Warren McCulloch**와 수학자 **Walter Pitts**에 의해 1943년에 처음 소개되었다. <br>\n",
    "이들은 생물학적 뉴런이 동물 두뇌에서 함께 작동하여 복잡한 계산을 수행하는 방법에 대한 간단한 계산 모델을 제시했고 이것이 최초의 인공 신경 네트워크 아키텍쳐였다. \n",
    "<br>\n",
    "이후 암흑기가 찾아왔다가 1980년대 초 ANN에 대한 관심이 증가하였다. 그러나 1990년대 Support Vector Machine과 같은 다른 기계학습 기술이 더 나은 결과와 이론적 토대를 제공한 것처럼 보였으므로 대부분의 연구자가 선호하게 되었다. <br>\n",
    "\n",
    "그러나 우리는 이제 ANN의 또다른 파장을 목격하고 있다. ANN이 영향력이 있을것이라 생각하는 이유는 다음과 같다.<br>\n",
    "- 현재 신경 네트워크를 학습하는 데 사용할 수 있는 방대한 양의 데이터가 있으며, ANN은 매우 크고 복잡한 문제에 대해 다른 ML 기법보다 대개 성능이 우수하다. \n",
    "- 1990년대 이래로 컴퓨팅 능력이 엄청나게 증가하였기 때문에 대규모 신경 네트워크를 학습 할 수 있다. \n",
    "- 학습 알고리즘이 개선되었다.\n",
    "- ANN의 이론적 한계 중 일부는 실제로 양성(benign)으로 판명되었다. -> ANN 학습이 지역최적화 상태로 멈춰있어서 한계가 있다고 생각하지만 실제로 이런 경우는 매우 드물다는 것이 밝혀졌다. (그러한 경우, 오히려 글로벌 최적화에 더 가까움)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Biological Neurons\n",
    "<img src='10-1.PNG'>\n",
    "동물의 대뇌피질(뇌)에서 발견되는 세포로 세포핵(Nucleus)와 세포체(Cell Body)로 구성되어 있다. <br>\n",
    "수상돌기(Dendrite)와 축색돌기(axon)을 포함하고 이 축색돌기가 다른 뉴런의 수상돌기와 연결된다. <br>\n",
    "이러한 시냅스를 통해 전지적 자극으로 신호를 받는다. <br>\n",
    "\n",
    "생물학적 뉴런은 간단한 방식으로 행동하는 것처럼 보이지만 실제로는 수십억개의 뉴런으로 구성된 광대한 네트워크로 구성되어 있고 각 뉴런은 일반적으로 수천개의 다른 뉴런과 연결되어 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logical Computations with Neurons\n",
    "Warren McCulloch와 Walter Pitts가 제안한 뉴런 모델 ('인공뉴런')<br>\n",
    "이들이 제안한 인공뉴런은 하나 이상의 이진(on/off)입력과 하나의 이진 출력을 가지는 상태이다. <br>\n",
    "<img src='10-2.PNG'><br>\n",
    "\n",
    "    1) 첫번째 네트워크는 간단한 identity function <br>\n",
    "    뉴런 A가 활성화되면 C도 활성화된다. 뉴런 A가 꺼져있으면 C도 꺼져있다. <br>\n",
    "    \n",
    "    2) 두번째 네트워크는 논리적 AND를 수행한다. <br>\n",
    "    뉴런 C는 A와 B가 활성화 된 경우에만 활성화된다. <br>\n",
    "    \n",
    "    3) 세번째 네트워크는 논리적 OR를 수행한다.<br>\n",
    "    뉴런 C는 뉴런 A 또는 B가 활성화 된 경우 활성화된다. <br>\n",
    "    \n",
    "    4) 입력 연결이 뉴런의 활동을 억제할수 있다고 가정하면 네번째는 약간 더 복잡한 논리 명제를 계산한다. <br>\n",
    "    뉴런 A가 활성화되고 뉴런 B가 꺼져있으면 뉴런 C가 활성화된다. <br>\n",
    "    뉴런 A가 항상 활성화되어 있으면 논리적 NOT을 얻는다. (B가 꺼져있으면 C는 활성화, 또는 그 반대)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Perceptron\n",
    "Perceptron은 Frank Rosenblatt가 1957년에 발명한 가장 단순한 ANN 아키텍쳐중 하나이다. <br>\n",
    "\n",
    "### LTU\n",
    "**선형 임계값 단위(LTU;Linear Threshold Unit)** 라고 부르는 약간 다른 인공뉴런이다. \n",
    "<img src='10-3.PNG'>\n",
    "\n",
    "Input과 output은 숫자가 되고 (on/off 대신) 각각의 input 연결은 weight와 연관된다. <br>\n",
    "LTU는 input값에 대해 가중 합($Z=W_1X_1+W_2X_2+\\cdots+W_nX_n$)을 계산하고 그 합에 step function을 적용($h_w(X)=step(Z)$) 결과를 출력한다. \n",
    "\n",
    "Perceptron에서 가장 많이 쓰이는 step function은 **Heaviside step function**이다. <br>\n",
    "$$heaviside(Z)={{0  if z<0}\\choose {1 if z\\geq0}}$$\n",
    "\n",
    "간단한 이진 분류에는 single LTU를 사용할 수 있다. <br>\n",
    "Input의 선형 조합(linear combination)을 계산하고, 결과가 임계 값을 초과하는 경우 양수 클래스를 출력하거나, <br>\n",
    "그렇지 않으면(Logistic Regression 분류기 또는 선형 SVM과 같이) 음수 클래스를 출력한다.<br>\n",
    "예를 들어, 단일 LTU를 사용하여 꽃잎의 길이와 너비를 기반으로 홍채 꽃을 분류 할 수 있다. <br>\n",
    "**LTU를 학습한다는 것은 w0, w1, 그리고 w2에 대한 올바른 값을 찾는 것을 의미한다. **\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론\n",
    "**퍼셉트론**은 LTU의 단일 층으로 구성되며, 각 뉴런은 모든 입력이 연결된다.  \n",
    "<img src='10-4.PNG'>\n",
    "이러한 연결은 **input neurons**로 불리는 특별한 passthrough neurons로 표현되고 input neurons는 입력값이 무엇이든 상관없이 출력한다. <br>\n",
    "\n",
    " 또한, 추가 bias feature가 일반적으로 추가된다 ($X_0=1$). 이 bias feature는 일반적으로 항상 1을 출력하는 bias neuron이라는 특별한 유형의 뉴런을 사용하여 표현된다. <br>\n",
    "\n",
    "위의 그림은 두 개의 입력과 세 개의 출력을 갖는 퍼셉트론을 나타낸다.<br>\n",
    "이 퍼셉트론은 인스턴스를 동시에 세 가지 다른 이진 클래스로 분류할수 있으므로 다중 출력 분류기(Multioutput classifier)이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론의 학습\n",
    "Frank Rosenblatt가 제안한 퍼셉트론 학습 알고리즘은 Hebb's rule에 크게 영향을 받았다. <br>\n",
    "\n",
    "Hebb's rule은 **생물학 뉴런이 종종 다른 뉴런을 유발할 때 이 두 뉴런간의 연결이 강해진다**는 것으로 <br>\n",
    " **\"동일한 출력을 가질 때마다 두 뉴런 사이의 연결 가중치가 증가한다\"** 는 뜻이다.\n",
    " \n",
    "보다 구체적으로, 퍼셉트론은 한 번에 하나의 학습 인스턴스로 공급되며, 각 인스턴스에 대해 예측을 한다.<br> \n",
    "잘못된 예측을 산출한 모든 출력 뉴런에 대해, 올바른 출력 예측에 기여한 입력의 연결 가중치를 강화한다. <br>\n",
    "\n",
    "$$<Hebb's Rule>$$\n",
    "$$W_{i,j}^{(next step)} = W_{i,j}+\\eta (y_j-\\hat y_j)x_i$$\n",
    "\n",
    "- $w_{i,j}$ 는 i번째 input neuron과 j번째 output neuron 사이의 연결 가중치이다.\n",
    "- $x_i$는 현재 학습 인스턴스의 i번째 입력 값이다.\n",
    "- $\\hat y_j$는 현재 학습 인스턴스를 위한, j번째 output neuron의 output이다. (예측)\n",
    "- $y_j$는 현재 학습 인스턴스를 위한 output neuron의 j번째 target output이다. (답)\n",
    "- $\\eta$는 학습률(learning rate)이다.\n",
    "\n",
    "각 출력 뉴런의 결정 경계(decision boundary)는 선형이므로, 퍼셉트론은 복잡한 패턴을 학습할 수 없다. (Logistic Regression 분류기와 비슷함)<br>\n",
    "\n",
    "그러나 학습 인스턴스가 선형으로 분리될 수 있다면 Rosenblatt는 이 알고리즘이 솔루션으로 수렴된다는 것을 입증했다.??<br> \n",
    "이것을 Perceptron convergence theorem 이라 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons\n",
    " scikit-learn은 단일 LTU 네트워크를 구현하는 Perceptron 클래스를 제공한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ejjch\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ejjch\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\contour.py:967: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure perceptron_iris_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUzLsMXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21973d950f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap, linewidth=5)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 scikit-learn의 Perceptron 클래스는 loss = 'perceptron', learning_rate='constant', eta0=1 (학습률=learning rate), 그리고 penalty = None(no regularization) 과 같은 하이퍼 파라미터와 함께 SGDClassifier를 사용하는 것과 같다. \n",
    "\n",
    "Logistic Regression 분류기와 달리, 퍼셉트론은 클래스 확률을 출력하지 않고 단지 hard threshold 값을 기반으로 예측을 하기 때문에 Logistic regression이 퍼셉트론보다 선호된다.\n",
    "\n",
    " Perceptrons의 심각한 약점은 Exclusive OR(XOR) 분류 문제 등의 사소한 문제를 해결할 수 없다는 사실을 강조했다. \n",
    "\n",
    "물론 이것은 Logistic Regression 분류기와 같은 다른 선형 분류 모델에서도 마찬가지이지만, 퍼셉트론에서 더 많은 것을 기대했던 연구자들은 실망감이 컸다. <br>\n",
    "결과적으로 많은 연구자들이 논리(logic), 문제해결(problem solving) 및 검색(search)과 같은 더 높은 수준의 문제를 다룰수 있는 신경망 연구(connectionism)를 중단했었다. \n",
    "\n",
    "<img src='10-5.PNG'>\n",
    "\n",
    "그러나 여러가지 퍼셉트론을 스태킹(stacking)하면 퍼셉트론의 한계점 중 일부를 제거할 수 있는데 이러한 결과를 MLP(Multi-Layer Perceptron)이\n",
    "라고 부른다. <br>\n",
    "특히 MLP의 출력을 계산하여 확인할 수 있기 때문에 XOR 문제를 해결할 수 있다. (그림)<br>\n",
    "입력 (0,0) 또는 (1,1) 네트워크는 0을 출력하고, 입력 (0,1) 또는 (1,0) 네트워크는 1을 출력한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multi-Layer Perceptron and Backpropagation\n",
    "MLP는 하나의 input layer와 hidden layer라 불리는 하나 이상의 LTU layer, 그리고 output layer라 불리는 LTU의 최종 layer로 구성된다. <br>\n",
    "output layer를 제외한 모든 layer는 bias neuron을 포함하며, 다음 layer에 완전히 연결(fully connected)된다.  <br>\n",
    "ANN에 2개 이상의 hidden layers가 있으면 DNN(Deep Neural Network)라고 부른다.\n",
    "<img src = '10-6.PNG'>\n",
    "\n",
    "1986년에 backpropagation training algorithm 이 소개되면서 MLP 학습 방법이 발전되었다. <br>\n",
    "이 방법을 reverse-mode autodiff를 이용하여 Gradient Descent로 설명해보자. \n",
    "\n",
    "### Backpropagation \n",
    "1) 각 학습 instance는 네트워크에 feed되고 연속 layer의 모든 뉴런에 대해 output을 계산한다.(Foward pass)<br>\n",
    "2) 그 다음, 네트워크의 output 오차를 측정한다. (실제 출력값과 예측값의 비교를 통해)<br>\n",
    "3) 이를 통해 이전의 hidden layer의 각 뉴런이 출력 뉴런의 오차에 얼마나 기여하는지를 계산한다. <br>\n",
    "4) 계산한 오차 기여도를 그 전 hidden layer의 각 뉴런에서 얼마나 영향을 준건지 계산하면서 input layer에 다다를 때까지 반복해서 계산한다. \n",
    "\n",
    "이러한 reverse pass는 네트워크에서 역방향으로 (backward) error gradient를 전파(propagating)함으로써 네트워크의 모든 연결 가중치에 대한\n",
    "error gradient를 효율적으로 측정한다.\n",
    "\n",
    "5) 역전파 알고리즘의 마지막 단계는 앞에서 측정한 error gradient를 사용하여 네트워크의 모든 연결 가중치에 대한 Gradient Descent를 하는 단계다.\n",
    "\n",
    "**짧게 말해, 각각의 학습 인스턴스에 대해 먼저 예측(forward pass)을 진행하고, 오류를 측정 한 다음, 역으로 각 layer를 거쳐 각 연결에서 error 기여도를 측정(reverse pass)하고, 마지막으로 error를 줄이기 위해 연결 가중치를 미세하게 조정한다(Gradient Descent step).**\n",
    "\n",
    "Backpropagation 알고리즘을 위해 MLP의 아키텍쳐를 변경하였다. <br>\n",
    "step function을 Logistic function $[\\sigma(z) = 1 / (1 + exp (-z))]$ 으로 대체하여 Gradient Descent를 수행가능하게 변경하였다. (기존의 평평했던 segments를 경사가 있는 function으로 대체??)<br>\n",
    "-> Logistic function이 아닌 다른 활성화 함수(Activation functions)도 가능\n",
    "\n",
    "### Activation Functions\n",
    "#### 1. The hyperbolic tangent function : $tanh(z)=2\\sigma{(2z)}-1$\n",
    "     - Logistic function과 마찬가지로 S자 형이며 연속적이고, 미분 가능하지만 출력 값의 범위는 -1에서부터 1이다. \n",
    "       (logistic function의 경우 0에서1임)\n",
    "     - 이것은 각 layer의 출력이 훈련 시작 시, more or less하게 정규화되도록 하는 경향이 있다. (centered around 0).\n",
    "     - 이는 수렴 속도를 높이는 데 종종 도움이 된다.\n",
    "     \n",
    "     \n",
    "#### 2. The ReLU function : $ReLU(z)=max(0,z)$\n",
    "    - 연속적이지만 z=0 일 때 미분 할 수 없다.(기울기가 갑자기 변하기 때문에, gradient descent가 바운스 될 수 있음)\n",
    "    - 매우 잘 작동하며, 계산 속도가 빠르다는 이점이 있다.\n",
    "    - 무엇보다 최대 출력 값을 갖고 있지 않다는 사실은 gradient descent 동안 일부 문제를 줄이는 데 도움이 된다.(11강에서 설명)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure activation_functions_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAEYCAYAAADMNRC5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhHDa/wO/jsL3o9WIqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21977dfa4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"activation_functions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 활성화 함수와 도함수를 보여준다<br>\n",
    "\n",
    "MLP 는 분류(classification)에 주로 사용되고 각 출력은 바이너리 클래스에 해당한다. <br>\n",
    "만약 exclusive class (숫자 이미지의 경우 0~9)일 경우 output layer는 일반적으로 개별 활성화 함수를 softmax 함수로 대체하여 수정된다<br>\n",
    "\n",
    "각 뉴런의 출력은 해당 클래스의 예상 확률에 해당되며 신호는 input에서 output으로 한 방향으로만 흐른다.<br>\n",
    "이러한 아키텍쳐를 \"Feedforward Neural Network\"라 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAEMCAYAAACfoCGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwdgJbcJzZ/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21977de0cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "    \n",
    "#### 생물학적 뉴런은 대략 sigmod(S자 형태)의 활성화 기능을 구현하는 것으로 보이므로 연구원들은 오랫동안 sigmoid 함수를 고수했다.  그러나 ANN에서 일반적으로 ReLU가 더 잘 작동하는것으로 판별됐다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training an MLP with Tensorflow's High-Level API\n",
    "텐서플로우를 사용하여 MLP를 학습하는 가장 간단한 방법은 scikit-learn-compatible API를 제공하는 고수준 API인 `tf.Learn`을 사용하는 것\n",
    "\n",
    "`DNNClassifier` 클래스를 사용하면 hidden layer의 개수가 많은 심층 신경 네트워크(deep neural network)와 예상되는 클래스 확률을 출력 할 softmax output layer의 학습을 쉽게 할 수 있다.\n",
    "\n",
    "\n",
    "예를 들어, 아래 코드는 두 개의 hidden layer(하나는 300개의 뉴런이 있고, 다른 하나는 100개의 뉴런)와 10개의 뉴런을 가지고 있는 softmax\n",
    "output layer로 분류되도록 DNN을 학습한다.\n",
    "\n",
    "## FNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using tf.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\tmps7_7rfnh\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002197AE03400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Public\\\\Documents\\\\ESTsoft\\\\CreatorTemp\\\\tmps7_7rfnh'}\n",
      "WARNING:tensorflow:From c:\\users\\ejjch\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\tmps7_7rfnh\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.36404, step = 1\n",
      "INFO:tensorflow:global_step/sec: 407.126\n",
      "INFO:tensorflow:loss = 0.311432, step = 101 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.538\n",
      "INFO:tensorflow:loss = 0.265409, step = 201 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.408733, step = 301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.244357, step = 401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.238858, step = 501 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.091827, step = 601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.123374, step = 701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.196473, step = 801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.0932024, step = 901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.196834, step = 1001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.194408, step = 1101 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.152048, step = 1201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.149761, step = 1301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.0647763, step = 1401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.783\n",
      "INFO:tensorflow:loss = 0.0727728, step = 1501 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.120371, step = 1601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0426907, step = 1701 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.4\n",
      "INFO:tensorflow:loss = 0.148324, step = 1801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.073107, step = 1901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.0638611, step = 2001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.834\n",
      "INFO:tensorflow:loss = 0.0233887, step = 2101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0329285, step = 2201 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.0519914, step = 2301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.0577268, step = 2401 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.045\n",
      "INFO:tensorflow:loss = 0.084227, step = 2501 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.0315869, step = 2601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0121763, step = 2701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:loss = 0.0630663, step = 2801 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.153\n",
      "INFO:tensorflow:loss = 0.0913481, step = 2901 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.0138151, step = 3001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.216\n",
      "INFO:tensorflow:loss = 0.0337465, step = 3101 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.0132512, step = 3201 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.0321816, step = 3301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.4\n",
      "INFO:tensorflow:loss = 0.143895, step = 3401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0897496, step = 3501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.157295, step = 3601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.56\n",
      "INFO:tensorflow:loss = 0.03669, step = 3701 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.0122543, step = 3801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.152421, step = 3901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.107787, step = 4001 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0485792, step = 4101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0590532, step = 4201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.158572, step = 4301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.114563, step = 4401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.079\n",
      "INFO:tensorflow:loss = 0.0187132, step = 4501 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 0.0182185, step = 4601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00904818, step = 4701 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0186206, step = 4801 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.926\n",
      "INFO:tensorflow:loss = 0.0834735, step = 4901 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.774\n",
      "INFO:tensorflow:loss = 0.0451745, step = 5001 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.402\n",
      "INFO:tensorflow:loss = 0.00802126, step = 5101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.0236921, step = 5201 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.781\n",
      "INFO:tensorflow:loss = 0.040991, step = 5301 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.539\n",
      "INFO:tensorflow:loss = 0.0607277, step = 5401 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.782\n",
      "INFO:tensorflow:loss = 0.0441553, step = 5501 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.0769239, step = 5601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0198653, step = 5701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00881232, step = 5801 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.113\n",
      "INFO:tensorflow:loss = 0.110585, step = 5901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.891\n",
      "INFO:tensorflow:loss = 0.0857567, step = 6001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.0120617, step = 6101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:loss = 0.022921, step = 6201 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.123\n",
      "INFO:tensorflow:loss = 0.0707142, step = 6301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.299\n",
      "INFO:tensorflow:loss = 0.0212568, step = 6401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00796753, step = 6501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.0281497, step = 6601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.045\n",
      "INFO:tensorflow:loss = 0.0216029, step = 6701 (0.233 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.0129809, step = 6801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.0126797, step = 6901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.05\n",
      "INFO:tensorflow:loss = 0.0166421, step = 7001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.299\n",
      "INFO:tensorflow:loss = 0.00448675, step = 7101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0508161, step = 7201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.4\n",
      "INFO:tensorflow:loss = 0.00550252, step = 7301 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.0154965, step = 7401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.004822, step = 7501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.888\n",
      "INFO:tensorflow:loss = 0.0131625, step = 7601 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.00680886, step = 7701 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.00376618, step = 7801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.0131479, step = 7901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.121\n",
      "INFO:tensorflow:loss = 0.00631671, step = 8001 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.605\n",
      "INFO:tensorflow:loss = 0.0245089, step = 8101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0208505, step = 8201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.522\n",
      "INFO:tensorflow:loss = 0.04197, step = 8301 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.833\n",
      "INFO:tensorflow:loss = 0.0136715, step = 8401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.0110502, step = 8501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00604934, step = 8601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0065747, step = 8701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:loss = 0.00738027, step = 8801 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.00280681, step = 8901 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.56\n",
      "INFO:tensorflow:loss = 0.015022, step = 9001 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00840854, step = 9101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.889\n",
      "INFO:tensorflow:loss = 0.00372718, step = 9201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.423\n",
      "INFO:tensorflow:loss = 0.0134235, step = 9301 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:loss = 0.034022, step = 9401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.00841827, step = 9501 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.425\n",
      "INFO:tensorflow:loss = 0.015819, step = 9601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.347\n",
      "INFO:tensorflow:loss = 0.0086599, step = 9701 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.426\n",
      "INFO:tensorflow:loss = 0.00439482, step = 9801 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.042\n",
      "INFO:tensorflow:loss = 0.0174038, step = 9901 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.938\n",
      "INFO:tensorflow:loss = 0.0208312, step = 10001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 0.00381713, step = 10101 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.00676587, step = 10201 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00574352, step = 10301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00939435, step = 10401 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00275532, step = 10501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.00952128, step = 10601 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.0303758, step = 10701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0115768, step = 10801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00465772, step = 10901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.0293584, step = 11001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00492727, step = 11101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.079\n",
      "INFO:tensorflow:loss = 0.000853527, step = 11201 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.0139262, step = 11301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00881559, step = 11401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.0186049, step = 11501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.076\n",
      "INFO:tensorflow:loss = 0.000492324, step = 11601 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.939\n",
      "INFO:tensorflow:loss = 0.00230341, step = 11701 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.000418936, step = 11801 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.00709947, step = 11901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.889\n",
      "INFO:tensorflow:loss = 0.000176346, step = 12001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00352114, step = 12101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00409825, step = 12201 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:loss = 0.00442711, step = 12301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.000686727, step = 12401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.00342111, step = 12501 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00143894, step = 12601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.00396524, step = 12701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.126\n",
      "INFO:tensorflow:loss = 0.00715362, step = 12801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.152\n",
      "INFO:tensorflow:loss = 0.00564594, step = 12901 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.347\n",
      "INFO:tensorflow:loss = 0.00317152, step = 13001 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.08\n",
      "INFO:tensorflow:loss = 0.00411803, step = 13101 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.566\n",
      "INFO:tensorflow:loss = 0.00683057, step = 13201 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.755\n",
      "INFO:tensorflow:loss = 0.00482892, step = 13301 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:loss = 0.00194253, step = 13401 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.418\n",
      "INFO:tensorflow:loss = 0.00725991, step = 13501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00496594, step = 13601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.00231069, step = 13701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.604\n",
      "INFO:tensorflow:loss = 0.00758488, step = 13801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00351695, step = 13901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00250569, step = 14001 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00576778, step = 14101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.834\n",
      "INFO:tensorflow:loss = 0.0106178, step = 14201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.748\n",
      "INFO:tensorflow:loss = 0.00184563, step = 14301 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:loss = 0.000657787, step = 14401 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000907568, step = 14501 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.00308903, step = 14601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000958802, step = 14701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00119474, step = 14801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.216\n",
      "INFO:tensorflow:loss = 0.00213329, step = 14901 (0.235 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.0011101, step = 15001 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00242632, step = 15101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.00159225, step = 15201 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.783\n",
      "INFO:tensorflow:loss = 0.0014488, step = 15301 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:loss = 0.00376972, step = 15401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.402\n",
      "INFO:tensorflow:loss = 0.00406733, step = 15501 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.834\n",
      "INFO:tensorflow:loss = 0.00472252, step = 15601 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.0146699, step = 15701 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.748\n",
      "INFO:tensorflow:loss = 0.00153426, step = 15801 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.000447847, step = 15901 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00656253, step = 16001 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.0043496, step = 16101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.43\n",
      "INFO:tensorflow:loss = 7.70298e-05, step = 16201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00260926, step = 16301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.56\n",
      "INFO:tensorflow:loss = 0.00155471, step = 16401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.0015937, step = 16501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.346\n",
      "INFO:tensorflow:loss = 0.00472044, step = 16601 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.245\n",
      "INFO:tensorflow:loss = 0.00249327, step = 16701 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 0.00237052, step = 16801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00251921, step = 16901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.935\n",
      "INFO:tensorflow:loss = 0.00285329, step = 17001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.348\n",
      "INFO:tensorflow:loss = 0.000563493, step = 17101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00264452, step = 17201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.539\n",
      "INFO:tensorflow:loss = 0.000915113, step = 17301 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.079\n",
      "INFO:tensorflow:loss = 0.00186997, step = 17401 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.204\n",
      "INFO:tensorflow:loss = 0.00155757, step = 17501 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.56\n",
      "INFO:tensorflow:loss = 0.000356618, step = 17601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.211\n",
      "INFO:tensorflow:loss = 0.000703532, step = 17701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.839\n",
      "INFO:tensorflow:loss = 0.000502199, step = 17801 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.00201421, step = 17901 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.00172619, step = 18001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.56\n",
      "INFO:tensorflow:loss = 0.000986052, step = 18101 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.215\n",
      "INFO:tensorflow:loss = 0.00447541, step = 18201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.0146146, step = 18301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.782\n",
      "INFO:tensorflow:loss = 0.00289675, step = 18401 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.422\n",
      "INFO:tensorflow:loss = 0.0022742, step = 18501 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.299\n",
      "INFO:tensorflow:loss = 0.00423942, step = 18601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.144\n",
      "INFO:tensorflow:loss = 0.000945454, step = 18701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00149365, step = 18801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.427\n",
      "INFO:tensorflow:loss = 0.00309862, step = 18901 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.748\n",
      "INFO:tensorflow:loss = 0.00134573, step = 19001 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.889\n",
      "INFO:tensorflow:loss = 0.000693691, step = 19101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.000465131, step = 19201 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00558755, step = 19301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000528183, step = 19401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.375\n",
      "INFO:tensorflow:loss = 0.00208042, step = 19501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.426\n",
      "INFO:tensorflow:loss = 0.000694155, step = 19601 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.215\n",
      "INFO:tensorflow:loss = 0.000119371, step = 19701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.4\n",
      "INFO:tensorflow:loss = 0.00051242, step = 19801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00184305, step = 19901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00206445, step = 20001 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:loss = 0.0003063, step = 20101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.59\n",
      "INFO:tensorflow:loss = 0.00195141, step = 20201 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.831\n",
      "INFO:tensorflow:loss = 0.000959544, step = 20301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.00013434, step = 20401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.0003517, step = 20501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.044\n",
      "INFO:tensorflow:loss = 0.00149112, step = 20601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00112818, step = 20701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.044\n",
      "INFO:tensorflow:loss = 0.00154887, step = 20801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.05\n",
      "INFO:tensorflow:loss = 0.00139391, step = 20901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.215\n",
      "INFO:tensorflow:loss = 0.00281828, step = 21001 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.00136329, step = 21101 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00240587, step = 21201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.429\n",
      "INFO:tensorflow:loss = 0.00113844, step = 21301 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.149\n",
      "INFO:tensorflow:loss = 0.00262636, step = 21401 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000237559, step = 21501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.783\n",
      "INFO:tensorflow:loss = 0.00151222, step = 21601 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.000995086, step = 21701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.000349444, step = 21801 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000656097, step = 21901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000148364, step = 22001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.888\n",
      "INFO:tensorflow:loss = 0.000531831, step = 22101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:loss = 0.00140872, step = 22201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.217\n",
      "INFO:tensorflow:loss = 0.00243447, step = 22301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.833\n",
      "INFO:tensorflow:loss = 0.00220339, step = 22401 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.403\n",
      "INFO:tensorflow:loss = 0.00157356, step = 22501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.745\n",
      "INFO:tensorflow:loss = 0.00364198, step = 22601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.08\n",
      "INFO:tensorflow:loss = 0.000852597, step = 22701 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.00109362, step = 22801 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.75\n",
      "INFO:tensorflow:loss = 0.00240539, step = 22901 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000654596, step = 23001 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00295467, step = 23101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.00217089, step = 23201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.00169613, step = 23301 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000720154, step = 23401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.423\n",
      "INFO:tensorflow:loss = 0.000805685, step = 23501 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.256\n",
      "INFO:tensorflow:loss = 0.000631053, step = 23601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.000255326, step = 23701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.00180432, step = 23801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000976085, step = 23901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.00113664, step = 24001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.937\n",
      "INFO:tensorflow:loss = 0.000741892, step = 24101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000928554, step = 24201 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.126\n",
      "INFO:tensorflow:loss = 0.000218442, step = 24301 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.783\n",
      "INFO:tensorflow:loss = 0.00173174, step = 24401 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.000569286, step = 24501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.204\n",
      "INFO:tensorflow:loss = 0.000322807, step = 24601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.614\n",
      "INFO:tensorflow:loss = 0.00111121, step = 24701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.00132868, step = 24801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.00235335, step = 24901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000118122, step = 25001 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00184492, step = 25101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.429\n",
      "INFO:tensorflow:loss = 0.00320799, step = 25201 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.000183373, step = 25301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.299\n",
      "INFO:tensorflow:loss = 0.000734714, step = 25401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.00117328, step = 25501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00101388, step = 25601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000994076, step = 25701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00148109, step = 25801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.836\n",
      "INFO:tensorflow:loss = 0.00150336, step = 25901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 4.42679e-05, step = 26001 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000945769, step = 26101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.000692925, step = 26201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.000701611, step = 26301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.047\n",
      "INFO:tensorflow:loss = 0.00164209, step = 26401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000905918, step = 26501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000519783, step = 26601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 1.40954e-05, step = 26701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.75\n",
      "INFO:tensorflow:loss = 0.000842135, step = 26801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.000808341, step = 26901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000642265, step = 27001 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000423766, step = 27101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000671817, step = 27201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00108788, step = 27301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000168051, step = 27401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00143462, step = 27501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.000935573, step = 27601 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.000289417, step = 27701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 0.000623281, step = 27801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 0.000400492, step = 27901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.00141883, step = 28001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.000513484, step = 28101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.00133993, step = 28201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.000679669, step = 28301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.000811346, step = 28401 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.429\n",
      "INFO:tensorflow:loss = 0.00057602, step = 28501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000366546, step = 28601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.00086157, step = 28701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:loss = 0.00103206, step = 28801 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000274243, step = 28901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.216\n",
      "INFO:tensorflow:loss = 0.00182547, step = 29001 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.00104729, step = 29101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.001766, step = 29201 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.836\n",
      "INFO:tensorflow:loss = 0.00105772, step = 29301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000961037, step = 29401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.00102937, step = 29501 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.817\n",
      "INFO:tensorflow:loss = 0.000430005, step = 29601 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.217\n",
      "INFO:tensorflow:loss = 0.00025649, step = 29701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.000605404, step = 29801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.00077305, step = 29901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.000108064, step = 30001 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.539\n",
      "INFO:tensorflow:loss = 0.000590002, step = 30101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000234104, step = 30201 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.00065963, step = 30301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.539\n",
      "INFO:tensorflow:loss = 0.00115885, step = 30401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.000882715, step = 30501 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.00145138, step = 30601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.218\n",
      "INFO:tensorflow:loss = 0.000891694, step = 30701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.629\n",
      "INFO:tensorflow:loss = 0.00118, step = 30801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:loss = 0.00115266, step = 30901 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000961674, step = 31001 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.00149113, step = 31101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.000568497, step = 31201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000460989, step = 31301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.399\n",
      "INFO:tensorflow:loss = 0.000649023, step = 31401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.046\n",
      "INFO:tensorflow:loss = 0.000197947, step = 31501 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 6.59552e-05, step = 31601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.000625275, step = 31701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 9.4202e-05, step = 31801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.836\n",
      "INFO:tensorflow:loss = 0.000756386, step = 31901 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:loss = 0.000197061, step = 32001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.045\n",
      "INFO:tensorflow:loss = 0.000425281, step = 32101 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.00102074, step = 32201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.00041044, step = 32301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.000104019, step = 32401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000511087, step = 32501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000111053, step = 32601 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00126878, step = 32701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.299\n",
      "INFO:tensorflow:loss = 0.000895224, step = 32801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.077\n",
      "INFO:tensorflow:loss = 0.000406547, step = 32901 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000497633, step = 33001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.00210473, step = 33101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000945465, step = 33201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.000309007, step = 33301 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.00123292, step = 33401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.000225348, step = 33501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:loss = 0.000940695, step = 33601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000726792, step = 33701 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.00123973, step = 33801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.604\n",
      "INFO:tensorflow:loss = 0.00107691, step = 33901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.000640319, step = 34001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000919945, step = 34101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00121334, step = 34201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000127433, step = 34301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:loss = 0.000417725, step = 34401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000630038, step = 34501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.000360699, step = 34601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.00173927, step = 34701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:loss = 0.000371267, step = 34801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.046\n",
      "INFO:tensorflow:loss = 0.000374646, step = 34901 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.215\n",
      "INFO:tensorflow:loss = 0.000305932, step = 35001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:loss = 0.00104693, step = 35101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.000340343, step = 35201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000153641, step = 35301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.4\n",
      "INFO:tensorflow:loss = 0.000996451, step = 35401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.079\n",
      "INFO:tensorflow:loss = 0.000171532, step = 35501 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.000374124, step = 35601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000663798, step = 35701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.604\n",
      "INFO:tensorflow:loss = 0.000831119, step = 35801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.000574592, step = 35901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.402\n",
      "INFO:tensorflow:loss = 0.000313818, step = 36001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.00114753, step = 36101 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000859921, step = 36201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 9.09132e-05, step = 36301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.000575347, step = 36401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000190056, step = 36501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.000239809, step = 36601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.00044674, step = 36701 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.000904511, step = 36801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000720104, step = 36901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:loss = 0.000412932, step = 37001 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.000163695, step = 37101 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.045\n",
      "INFO:tensorflow:loss = 0.000264861, step = 37201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.000719457, step = 37301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:loss = 0.000339975, step = 37401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.213\n",
      "INFO:tensorflow:loss = 0.000324403, step = 37501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.402\n",
      "INFO:tensorflow:loss = 0.000306283, step = 37601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.000100169, step = 37701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:loss = 0.000432111, step = 37801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.052\n",
      "INFO:tensorflow:loss = 0.00140533, step = 37901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:loss = 0.000294866, step = 38001 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.00119604, step = 38101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000891358, step = 38201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:loss = 0.000129545, step = 38301 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.000193591, step = 38401 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.296\n",
      "INFO:tensorflow:loss = 0.00049303, step = 38501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.404\n",
      "INFO:tensorflow:loss = 0.000675174, step = 38601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.115\n",
      "INFO:tensorflow:loss = 0.000358051, step = 38701 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.781\n",
      "INFO:tensorflow:loss = 0.000242674, step = 38801 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.045\n",
      "INFO:tensorflow:loss = 0.00127899, step = 38901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.000262657, step = 39001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.000705544, step = 39101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.297\n",
      "INFO:tensorflow:loss = 0.000659797, step = 39201 (0.239 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 422.604\n",
      "INFO:tensorflow:loss = 0.000316944, step = 39301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.037\n",
      "INFO:tensorflow:loss = 0.000639012, step = 39401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.572\n",
      "INFO:tensorflow:loss = 0.000241011, step = 39501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:loss = 0.000744708, step = 39601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.82\n",
      "INFO:tensorflow:loss = 0.000178735, step = 39701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.89\n",
      "INFO:tensorflow:loss = 0.00115475, step = 39801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:loss = 0.00126455, step = 39901 (0.236 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\tmps7_7rfnh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000402969.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "# DNNClassifier 생성 , 2개의 hidden layer로 각각 300개의 뉴런, 100개의 뉴런, output layer는 10개의 뉴런\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "\n",
    "# 50개의 인스턴스 batch를 이용하여 40,000번의 반복 학습한다.\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\tmps7_7rfnh\\model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98209999999999997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터 세트에서 실행한 결과 정확도 98.2%를 달성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071487383848950564"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_pred_proba = y_pred['probabilities']\n",
    "log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNNClassifier 클래스는 ReLU 활성화 함수(activation_fn 파라미터를 설정하여 변경 가능)를 기반으로 모든 뉴런 layer를 만든다. \n",
    "\n",
    "output layer는 softmax 함수로 생성되고, cost function은 교차 엔트로피(cross entropy) 이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Training a DNN Using Plain Tensorflow\n",
    "\n",
    "네트워크 아키텍처를 보다 잘 제어하려면, 텐서플로우의 낮은 수준의 파이썬 API를 사용하는 것이 좋다.<br>\n",
    "API를 사용하기 전과 동일한 모델을 만들고 MNIST 데이터 세트에서 Mini-batch Gradient Descent를 구현한다.\n",
    "\n",
    " - 첫 번째 : 텐서플로우 그래프를 빌드하는 construction Phase(구축단계)\n",
    " - 두 번째 : execution phase(실행단계). 실제로 그래프를 실행하여 모델을 학습."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Constructuon phase\n",
    "- 텐서플로우 라이브러리 가져오기\n",
    "- 입력 및 출력 수 지정\n",
    "- 각 계층에서 hidden neurons의 수를 설정\n",
    "\n",
    "1) input과 target에 대한 placeholder를 생성 <br>\n",
    "2) neuron layer를 만드는 함수 생성<br>\n",
    "3) DNN을 만들기 위해 비용함수(cost function)를 정의<br>\n",
    "4) 최적화 도구(optimizer) 생성<br>\n",
    "5) 마지막으로 성능 측정(Performance measure)을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28*28  # MNIST  feature의 개수는 28*28(픽섹 당 하나의 feature)\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 placeholder 노드를 사용하여 학습데이터와 타겟을 나타낸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") # X는 2차원 텐서(행렬)\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "placeholder X는 input layer로 작동<br>\n",
    "execution phase에서 한 번에 하나의 학습 batch로 대체된다.\n",
    "\n",
    "두 개의 hidden layer와 output layer를 생성한다. 두 개의 hidden layer는 거의 동일하다. <br>\n",
    "차이점은 연결되는 input과 그들을 포함하는 뉴런의 개수\n",
    "\n",
    "output layer도 매우 유사하지만 ReLU 활성화 함수 대신 softmax 활성화 함수를 사용한다. 한 번에 하나의 layer를 만드는 데 사용할 neuron_layer() 함수를 만든다. 이는 입력, 뉴런 수, 활성화 함수 및 layer 이름을 지정하는 파라미터를 필요로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 코드 상세\n",
    "1) `with tf.name_scope(name)` : layer 이름을 사용하여 name scope을 만든다. 이 레이어에 대한 모든 계산 노드가 포함된다.<br>\n",
    "2) `n_inputs = int(X.ger_shape()[1])` : 입력 행렬(input matrix)의 shape에서 두 번째 차원의 크기를 불러와서 input의 수를 얻는다(첫 번째 차원은 인스턴스용)<br>\n",
    "3)  `stddev`, `init`, `W `부분 (세줄) \n",
    "    다음 세 줄은 가중치 행렬(weights matrix) (layer's kernel 이라고도 부름)을 hold할 변수 W를 만든다.<br>\n",
    "    각 입력과 각 뉴런사이의 모든 연결 가중치를 포함하는 2차원 텐서이다. 따라서 그 모양은 (n_inputs, n_neurons)이 된다. <br>\n",
    "    표준편차가 $2 /\\sqrt{n_(inputs)}$ 인 truncate 된 정규분포(Gaussian)를 사용하여 무작위로 초기화한다<br>\n",
    "    이 특정 표준편차를 사용하면 알고리즘이 훨씬 빨리 수렴하는 데 도움이 된다.(11장에서 더 자세히 논할 예정)<br>\n",
    "    Gradient Descent의 대칭(symmetric)을 피하기 위해 모든 hidden layer에 대해 연결 가중치를 임의로 초기화하는 것이 중요함.<br>\n",
    "4) `b = tf.Variable(tf.zeros([n_neurons]), name='bias')`:  0으로 초기화 된 bias에 대한 변수b 를 만든다. 뉴런 당 하나의 bias 파라미터가 있다.<br>\n",
    "5) `Z = tf.matmul(X, W) + b` : 그런 다음 Z = X · W + b를 계산하기 위한 부분 그래프(subgraph)를 만든다. 이 벡터화 된 구현은 한번에 batch 내 모든 인스턴스에 대해 입력 가중치 합계와 (weighted sums of the inputs) layer 내 각 뉴런에 대한 bias term을 효율적으로 계산한다<br>\n",
    "6) `if activation is not None: ~ return Z` :  마지막으로 tf.nn.relu (즉, max(0,Z))와 같은 활성화 파라미터가 제공되면, 코드는 활성화(activation) (Z)를 반환하거나 그렇지 않으면 Z만 반환한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  neuron layer 생성 코드 (DNN)\n",
    "- hidden layer 1은 X를 입력으로 사용\n",
    "- hidden layer 2는 X를 hidden layer 1의 출력을 입력으로 사용\n",
    "- output layer는 hidden layer 2의 출력을 입력으로 사용\n",
    "- 최적화를 위해 나중에 softmax 계산을 처리할 것이다\n",
    "\n",
    "\n",
    "텐서플로우에는 standard neural network layers를 만드는 데 유용한 많은 기능이 제공하기때문에 이전에 수행한 것처럼 neuron_layer()함수를 정의할 필요가 없을 경우가 있다. <br>\n",
    "예를 들어, 텐서플로우의 `tf.layers.dense()` 함수는 모든 input이 layer의 모든 neuron에 연결되는 fully connected layer를 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비용함수\n",
    "- 4장의 Softmax Regression과 마찬가지로 교차 엔트로피를 사용 (교차 엔트로피는 목표 클래스에 대한 낮은 확률을 추정하는 모델에 패널티를 줌)\n",
    "- 텐서플로에는 교차 엔트로피를 계산하는 몇 가지 함수를 제공한다. <br>\n",
    "<br>\n",
    "  * `sparse_softmax_cross_entropy_with_logits()` <br>\n",
    "  \"logits\" (softmax 활성화 함수를 거치기 전 네트워크의 output)을 기준으로 교차 엔트로피를 계산한다. <br>\n",
    "  0에서 클래스의 수에서 1을 뺀 범위의 정수 형태인 label을 예상한다. 각 인스턴스에 대해 교차 엔트로피를 포함하는 1차원 텐서를 제공한다. <br>\n",
    "   softmax 활성화 함수를 적용한 다음 교차 엔트로피를 계산하는 것과 동일하지만, 보다 효율적이며 0과 같은 logits과 같은 것에 대해 적절하게 처리한다. 그렇기 때문에 softmax 활성화 함수를 먼저 적용하지 않는다.\n",
    "   <br>\n",
    "<br>\n",
    "-  텐서플로우의 `reduce_mean()` 함수를 이용하여 모든 인스턴스에 대한 평균 교차 엔트로피를 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비용함수를 최소화하기 위해 모델의 파라미터를 조정하기 위한 GradientDescentOptimizer 정의\n",
    "(9장내용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성능평가\n",
    "- construction phase의 마지막 중요한 단계는 모델을 평가하는 방법을 지정하는 것이다. \n",
    "- 여기서는 단순히 성능 척도로서 accuracy를 이용\n",
    "- 각 인스턴스에 대해 가장 높은 logit이 target 클래스에 해당되는지에 대한 여부를 확인하여 신경망의 예측이 올바른지 확인한다.\n",
    "- 이를 위해 `in_top_k()` 함수를 사용할 수 있다. boolean 값의 1차원 텐서를 반환하기 때문에 이 boolean 값을 float형으로 캐스팅 한 다음 평균을 계산해야한다. \n",
    "- 이렇게 하면 네트워크의 전체 accuracy를 얻을 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수 초기화 \n",
    " 모든 변수를 초기화하는 노드를 만들어야하며, 학습 된 모델 파라미터 변수를 디스크에 저장하는 Saver도 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Phase\n",
    "이 부분은 construction phase보다 훨씬 더 짧고 간단하다.<br>\n",
    "텐서플로우는 데이터를 가져와서(fetch) 0에서 1사이로 크기를 조정(scale)하고, 셔플링하며, 하나의 mini-batch를 로드하는 간단한 함수를 제공하는 자체 helper를 제공한다. \n",
    "\n",
    "다음으로 실행하려는 epoch의 수와, mini-batch의 크기를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 코드는 텐서플로우 세션을 열고 모든 변수를 초기화하는 init 노드를 실행한다. \n",
    "- 그런 다음 기본 학습 루프를 실행한다. 각 epoch에서 학습 세트 크기에 해당하는 mini-batch의 수만큼 반복한다.\n",
    "- 각 mini-batch는 next_batch() 메소드를 통해 데이터를 가져온 후(fetch), 학습 작업(training operation)을 실행하고, 현재 mini-batch의 input 데이터와 target을 feeding 한다. \n",
    "- 그 다음으로, 각 epoch의 마지막에서 last mini-batch와 전체 테스트 세트의 모델을 평가하고, 결과를 출력한다. \n",
    "- 마지막으로 모델 파라미터 변수가 디스크에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Val accuracy: 0.9146\n",
      "1 Train accuracy: 0.94 Val accuracy: 0.9348\n",
      "2 Train accuracy: 0.92 Val accuracy: 0.9466\n",
      "3 Train accuracy: 0.96 Val accuracy: 0.9508\n",
      "4 Train accuracy: 0.92 Val accuracy: 0.9586\n",
      "5 Train accuracy: 0.94 Val accuracy: 0.9584\n",
      "6 Train accuracy: 0.98 Val accuracy: 0.9608\n",
      "7 Train accuracy: 0.96 Val accuracy: 0.9636\n",
      "8 Train accuracy: 0.92 Val accuracy: 0.9638\n",
      "9 Train accuracy: 0.96 Val accuracy: 0.965\n",
      "10 Train accuracy: 0.98 Val accuracy: 0.9686\n",
      "11 Train accuracy: 0.94 Val accuracy: 0.9686\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.9702\n",
      "13 Train accuracy: 0.94 Val accuracy: 0.9686\n",
      "14 Train accuracy: 1.0 Val accuracy: 0.9716\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.973\n",
      "16 Train accuracy: 1.0 Val accuracy: 0.9736\n",
      "17 Train accuracy: 0.98 Val accuracy: 0.9736\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.9752\n",
      "19 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "20 Train accuracy: 0.98 Val accuracy: 0.9748\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "22 Train accuracy: 1.0 Val accuracy: 0.9756\n",
      "23 Train accuracy: 1.0 Val accuracy: 0.9772\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.978\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.9772\n",
      "26 Train accuracy: 1.0 Val accuracy: 0.9778\n",
      "27 Train accuracy: 1.0 Val accuracy: 0.9762\n",
      "28 Train accuracy: 0.98 Val accuracy: 0.9774\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.9784\n",
      "30 Train accuracy: 1.0 Val accuracy: 0.9776\n",
      "31 Train accuracy: 1.0 Val accuracy: 0.9786\n",
      "32 Train accuracy: 0.98 Val accuracy: 0.9776\n",
      "33 Train accuracy: 0.98 Val accuracy: 0.9794\n",
      "34 Train accuracy: 0.98 Val accuracy: 0.978\n",
      "35 Train accuracy: 0.98 Val accuracy: 0.9768\n",
      "36 Train accuracy: 0.98 Val accuracy: 0.9794\n",
      "37 Train accuracy: 1.0 Val accuracy: 0.9784\n",
      "38 Train accuracy: 1.0 Val accuracy: 0.979\n",
      "39 Train accuracy: 1.0 Val accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
    "                                            y: mnist.validation.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 using the Neural Network\n",
    "- 신경망이 학습되었으므로, 이를 이용하여 예측할 수 있다.\n",
    "- 동일한 construction phase를 재사용 할 수 있지만, 다음과 같이 execution phase를 변경 해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # 디스크에서 모델 파라미터 변수를 로드\n",
    "    X_new_scaled = mnist.test.images[:20] #분류하기 위한 새로운 이미지 로드\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})#학습 데이터와 동일한 feature scaling을 해야한다.(0에서 1로 스케일 조정)\n",
    "    #그런다음, logits 노드를 평가 한다.\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "     #모든 예측된 클래스의 확률을 알고 싶다면 softmax()함수를 logits에 적용해야되지만, \n",
    "    #단지 클래스를 예측하기를 원한다면 argmax() 함수를 이용하면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Actual classes:   \", mnist.test.labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.2851015593374667&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0714285746216774\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;dnn/hidden1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;dnn/hidden1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;dnn/hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;dnn/hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.1154700517654419\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 21\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;dnn/hidden2/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;dnn/hidden2/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;dnn/hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;dnn/hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 37\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;dnn/outputs/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;dnn/outputs/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;dnn/outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;dnn/outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 300\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^dnn/hidden1/kernel/Assign&quot;\\n  input: &quot;^dnn/hidden1/bias/Assign&quot;\\n  input: &quot;^dnn/hidden2/kernel/Assign&quot;\\n  input: &quot;^dnn/hidden2/bias/Assign&quot;\\n  input: &quot;^dnn/outputs/kernel/Assign&quot;\\n  input: &quot;^dnn/outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/bias&quot;\\n        string_val: &quot;dnn/hidden1/kernel&quot;\\n        string_val: &quot;dnn/hidden2/bias&quot;\\n        string_val: &quot;dnn/hidden2/kernel&quot;\\n        string_val: &quot;dnn/outputs/bias&quot;\\n        string_val: &quot;dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.2851015593374667&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `dense()` instead of `neuron_layer()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function, except for a few minor differences:\n",
    "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
    "* the default `activation` is now `None` rather than `tf.nn.relu`.\n",
    "* a few more differences are presented in chapter 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.9053\n",
      "1 Train accuracy: 0.88 Test accuracy: 0.9206\n",
      "2 Train accuracy: 0.94 Test accuracy: 0.9301\n",
      "3 Train accuracy: 0.94 Test accuracy: 0.9397\n",
      "4 Train accuracy: 0.92 Test accuracy: 0.9451\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.9476\n",
      "6 Train accuracy: 0.92 Test accuracy: 0.9515\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.9546\n",
      "8 Train accuracy: 0.96 Test accuracy: 0.9569\n",
      "9 Train accuracy: 0.94 Test accuracy: 0.9605\n",
      "10 Train accuracy: 0.92 Test accuracy: 0.9619\n",
      "11 Train accuracy: 0.96 Test accuracy: 0.9631\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.9661\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9657\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.9669\n",
      "15 Train accuracy: 0.94 Test accuracy: 0.9682\n",
      "16 Train accuracy: 0.96 Test accuracy: 0.9701\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9696\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.97\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "n_batches = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.7224827313584268&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.7224827313584268&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fine-Tuning Neural Network Hyperparameters\n",
    "- 신경망의 유연성(flexibility)은 주요 단점 중 하나이며, 이를 조정하기 위한 많은 Hyperparameters(초매개변수)가 있다. \n",
    "- 간단한 MLP에서도 layer의 수, layer당 뉴런의 수, 각 layer에서 사용할 활성화 함수 유형, 가중치 초기화 로직 등 변경할 수 있다.\n",
    "\n",
    "**가장 적합한 Hyperparameters를 찾는 법**\n",
    " - 교차 검증(cross validation)과 함께 그리드서치를 사용 : 올바른 Hyperparameters를 찾을 수는 있지만, 튜닝 할 매개변수가 많고 대규모 데이터 세트에서 신경망을 학습하는 데 너무 많은 시간이 걸리게 됨\n",
    " - 무작위 검색(randomized search) 사용\n",
    " - Oscar와 같은 도구 사용 : 더 복잡한 알고리즘을 구현하여 훌륭한 Hyperparameters 빠르게 찾을 수 있도록 도와줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Number of Hidden Layers\n",
    "계층적 아키텍처(hierarchical architecture)는 DNN이 보다 신속하게 좋은 솔루션으로 수렴할 수 있을 뿐만 아니라, 새로운 데이터세트에서 일반화(generalize) 할 수 있는 능력을 향상시킨다. \n",
    "\n",
    "많은 문제에 대해 하나 또는 두 개의 hidden layer로 시작 할 수 있다.\n",
    " - 수백 개의 뉴런을 가진 hidden layer 하나를 사용하여 MNIST 데이터 세트에서 97%이상의 정확도 도달\n",
    " - 비슷한 양의 뉴런을 가진 hidden layer 두 개를 사용하여 98%의 정확도를 얻을 수 있음\n",
    " - 더 복잡한 문제의 경우, 학습 set이 과적합(overfitting)이 될 때까지 hidden layer의 수를 점차적으로 늘릴 수 있음\n",
    " - 큰 이미지 분류 또는 음성 인식과 같은 매우 복잡한 작업에는 일반적으로 수십 개의 layer가 있는 네트워크가 필요\n",
    " - 수백 개의 layer가 있지만 완전히 연결(fully connected)되어 있지 않은 경우도 있음. 이러한 네트워크를 처음부터 학습할 필요는 거의 없다. 유사한 작업을 수행하는 미리 학습 된 최신식의(state of the art) 네트워크의 일부를 재사용하는 것이 훨씬 더 빨라지고 적은 데이터를 필요로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Number of Neurons per Hidden Layer\n",
    "\n",
    " Input/Output layer의 뉴런 수는 작업에 필요한 input/output의 유형(type)에 따라 결정된다. \n",
    "예를 들어, MNIST 작업에는 28x28 = 784 의 input 뉴런과, 10개(0부터 9까지의 숫자)의 output 뉴런을 필요로 한다. Layer의 수와 마찬가지로 네트워크가 과적합이 시작될 때까지 점차적으로 뉴런의 수를 늘릴 수 있다. 일반적으로는 layer당 뉴런의 수보다 layer의 수를 증가시키는 것이, 본전을 뽑을 수 있을 만한 가치(bang for the buck)가 있다.\n",
    "\n",
    "더 간단한 접근법은 실제로 필요한 것보다 더 많은 layer와 뉴런을 가진 모델을 선택한 다음 early stopping을 사용하여 overfitting을 방지하는 방법이 있다.\n",
    "(예: 기타정규화(regularization)기법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Just like in the last exercise of chapter 9, try adding all the bells and whistles (i.e., save checkpoints, restore the last checkpoint in case of an interruption, add summaries, plot learning curves using TensorBoard, and so on)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create the deep net. It's exactly the same as earlier, with just one addition: we add a `tf.summary.scalar()` to track the loss and the accuracy during training, so we can view nice learning curves using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    loss_summary = tf.summary.scalar('log_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define the directory to write the TensorBoard logs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logdir = log_dir(\"mnist_dnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the `FileWriter` that we will use to write the TensorBoard logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! Why don't we implement early stopping? For this, we are going to need a validation set. Luckily, the dataset returned by TensorFlow's `input_data()` function (see above) is already split into a training set (60,000 instances, already shuffled for us), a validation set (5,000 instances) and a test set (5,000 instances). So we can easily define `X_valid` and `y_valid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = mnist.validation.images\n",
    "y_valid = mnist.validation.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, n = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 90.440% \tLoss: 0.35228\n",
      "Epoch: 5 \tValidation accuracy: 95.060% \tLoss: 0.17539\n",
      "Epoch: 10 \tValidation accuracy: 96.680% \tLoss: 0.12546\n",
      "Epoch: 15 \tValidation accuracy: 97.220% \tLoss: 0.10438\n",
      "Epoch: 20 \tValidation accuracy: 97.600% \tLoss: 0.08914\n",
      "Epoch: 25 \tValidation accuracy: 97.740% \tLoss: 0.08115\n",
      "Epoch: 30 \tValidation accuracy: 97.780% \tLoss: 0.07788\n",
      "Epoch: 35 \tValidation accuracy: 97.920% \tLoss: 0.07094\n",
      "Epoch: 40 \tValidation accuracy: 97.920% \tLoss: 0.06983\n",
      "Epoch: 45 \tValidation accuracy: 97.880% \tLoss: 0.06778\n",
      "Epoch: 50 \tValidation accuracy: 98.100% \tLoss: 0.06649\n",
      "Epoch: 55 \tValidation accuracy: 98.080% \tLoss: 0.06642\n",
      "Epoch: 60 \tValidation accuracy: 98.220% \tLoss: 0.06510\n",
      "Epoch: 65 \tValidation accuracy: 98.060% \tLoss: 0.06588\n",
      "Epoch: 70 \tValidation accuracy: 98.080% \tLoss: 0.06762\n",
      "Epoch: 75 \tValidation accuracy: 98.160% \tLoss: 0.06705\n",
      "Epoch: 80 \tValidation accuracy: 98.160% \tLoss: 0.06705\n",
      "Epoch: 85 \tValidation accuracy: 98.200% \tLoss: 0.06709\n",
      "Epoch: 90 \tValidation accuracy: 98.180% \tLoss: 0.06698\n",
      "Epoch: 95 \tValidation accuracy: 98.180% \tLoss: 0.06890\n",
      "Epoch: 100 \tValidation accuracy: 98.220% \tLoss: 0.06838\n",
      "Epoch: 105 \tValidation accuracy: 98.120% \tLoss: 0.06893\n",
      "Epoch: 110 \tValidation accuracy: 98.180% \tLoss: 0.06980\n",
      "Epoch: 115 \tValidation accuracy: 98.240% \tLoss: 0.07049\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_deep_mnist_model\"\n",
    "\n",
    "best_loss = np.infty\n",
    "epochs_without_progress = 0\n",
    "max_epochs_without_progress = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
    "        file_writer.add_summary(accuracy_summary_str, epoch)\n",
    "        file_writer.add_summary(loss_summary_str, epoch)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch:\", epoch,\n",
    "                  \"\\tValidation accuracy: {:.3f}%\".format(accuracy_val * 100),\n",
    "                  \"\\tLoss: {:.5f}\".format(loss_val))\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "            if loss_val < best_loss:\n",
    "                saver.save(sess, final_model_path)\n",
    "                best_loss = loss_val\n",
    "            else:\n",
    "                epochs_without_progress += 5\n",
    "                if epochs_without_progress > max_epochs_without_progress:\n",
    "                    print(\"Early stopping\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_deep_mnist_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, final_model_path)\n",
    "    accuracy_val = accuracy.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97839999"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
